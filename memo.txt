クローラーを作る手順

クローラーの仕事
  クローラ（Crawler）とは、ウェブ上の文書や画像などを周期的に取得し、自動的にデータベース化するプログラムである。「 ボット（Bot）」、「スパイダー」、「ロボット」などとも呼ばれる。 主に検索エンジンのデータベース、インデックス作成に用いられているほか、統計調査などの目的にも利用される。


  クローラー：HTTPプロトコルでコンテンツを取得する
  あなたの運営しているサーバーを含めた世界中のWebサーバーと通信し、そのサーバー内のコンテンツを取得していきます。通信手段はHTTP/HTTPSプロトコルなので、HTTP/HTTPSで取得できるものは、なんでも持っていきます（テキストファイル、CSSファイル、JavaScriptファイル、画像、Flash、PDFなど）。

  インデクサ：取得したコンテンツを解析し保存する
  取得したコンテンツの内容を解析します。ここで取得したコンテンツのキーワードやテーマを分析して読み取り、分析結果とそのファイル自体をデータベースに保存（インデックス）します。

  クエリサーバー：ユーザからの検索クエリ（キーワード）の結果ページを返す
  ユーザの検索キーワードに基づき、保存してあった解析結果を検索結果ページとして作成し、表示します。SEOの結果が反映される部分になります。
