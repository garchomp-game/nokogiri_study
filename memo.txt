クローラーの仕事
  クローラ（Crawler）とは、ウェブ上の文書や画像などを周期的に取得し、自動的にデータベース化するプログラムである。「 ボット（Bot）」、「スパイダー」、「ロボット」などとも呼ばれる。 主に検索エンジンのデータベース、インデックス作成に用いられているほか、統計調査などの目的にも利用される。

  クローラー：HTTPプロトコルでコンテンツを取得する
  あなたの運営しているサーバーを含めた世界中のWebサーバーと通信し、そのサーバー内のコンテンツを取得していきます。通信手段はHTTP/HTTPSプロトコルなので、HTTP/HTTPSで取得できるものは、なんでも持っていきます（テキストファイル、CSSファイル、JavaScriptファイル、画像、Flash、PDFなど）。

  インデクサ：取得したコンテンツを解析し保存する
  取得したコンテンツの内容を解析します。ここで取得したコンテンツのキーワードやテーマを分析して読み取り、分析結果とそのファイル自体をデータベースに保存（インデックス）します。

  クエリサーバー：ユーザからの検索クエリ（キーワード）の結果ページを返す
  ユーザの検索キーワードに基づき、保存してあった解析結果を検索結果ページとして作成し、表示します。SEOの結果が反映される部分になります。

railsで実現する方法を考えてみる。
・httpプロトコルでコンテンツの取得（open-url)
・取得したコンテンツを解析する。(nokogiri)
・解析したコンテンツを解析しデータベースに保存する。(mysql)
・実際の検索画面で、検索したキーワードを元に、キーワード絡むからhas_many出とってくる。

実際の処理の流れを考えてみる
・クローラーはコントローラーにて実装する。applicationコントローラーで実装したほうが良い可能性。
また、クローラー専用のコントローラーを開発してもいいかもしれない。この場合、どのように関連付けるかは要検討。

あるいはrailsアプリケーションと外部クローラー用ファイルを紐付ける方法もある。

